{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "BBBC036: 单文件三段式结构\n",
    "Part 1: 数据读取与准备\n",
    "Part 2: 模型\n",
    "Part 3: 训练与评估（含 main）\n",
    "\"\"\"\n",
    "# =========================\n",
    "# 通用导入\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 设置随机种子（保持原逻辑）\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Part 1) 数据读取与准备\n",
    "# ============================================================\n",
    "def load_from_HDF(fname):\n",
    "    \"\"\"Load data from a HDF5 file to a dictionary.\"\"\"\n",
    "    data = dict()\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        for key in f:\n",
    "            data[key] = np.asarray(f[key])\n",
    "            if isinstance(data[key][0], np.bytes_):\n",
    "                data[key] = data[key].astype(str)\n",
    "    return data\n",
    "\n",
    "\n",
    "class DrugResponseDataset(Dataset):\n",
    "    \"\"\"自定义数据集：返回 SMILES 向量、处理前特征、处理后特征\"\"\"\n",
    "    def __init__(self, smiles_embeddings, features_before, features_after):\n",
    "        self.smiles_embeddings = torch.tensor(smiles_embeddings, dtype=torch.float32)\n",
    "        self.features_before = torch.tensor(features_before, dtype=torch.float32)\n",
    "        self.features_after = torch.tensor(features_after, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'smiles': self.smiles_embeddings[idx],\n",
    "            'features_before': self.features_before[idx],\n",
    "            'features_after': self.features_after[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "def prepare_dataloaders(\n",
    "    smiles_pickle_path: str,\n",
    "    h5_path: str,\n",
    "    test_size: float = 0.1,\n",
    "    random_state: int = 42,\n",
    "    batch_size: int = 1024\n",
    "):\n",
    "    \"\"\"\n",
    "    加载HDF5与SMILES嵌入，过滤无嵌入样本，划分数据集并返回DataLoader及维度信息。\n",
    "    完全保持原脚本的数据处理与打印逻辑。\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    with open(smiles_pickle_path, 'rb') as f:\n",
    "        smi2emb = pickle.load(f)\n",
    "\n",
    "    cpg_data = load_from_HDF(h5_path)\n",
    "    print(f\"Data shapes: SMILES {cpg_data['canonical_smiles'].shape}, Target {cpg_data['target'].shape}, Control {cpg_data['control'].shape}\")\n",
    "\n",
    "    # 提取数据\n",
    "    smiles_list = cpg_data['canonical_smiles']\n",
    "    features_before = cpg_data['control']  # 处理前特征\n",
    "    features_after = cpg_data['target']    # 处理后特征\n",
    "\n",
    "    # 分布信息（保持原逻辑）\n",
    "    print(f\"Features before mean: {np.mean(features_before):.6f}, std: {np.std(features_before):.6f}\")\n",
    "    print(f\"Features after  mean: {np.mean(features_after):.6f}, std: {np.std(features_after):.6f}\")\n",
    "\n",
    "    # 将SMILES转为嵌入，过滤缺失\n",
    "    smiles_embeddings = []\n",
    "    invalid_indices = []\n",
    "    for i, smiles in enumerate(smiles_list):\n",
    "        if smiles in smi2emb:\n",
    "            smiles_embeddings.append(smi2emb[smiles].astype(np.float32))\n",
    "        else:\n",
    "            print(f\"Warning: SMILES '{smiles}' not found in embeddings, skipping index {i}.\")\n",
    "            invalid_indices.append(i)\n",
    "\n",
    "    smiles_embeddings = np.array(smiles_embeddings)\n",
    "    features_before = np.delete(features_before, invalid_indices, axis=0)\n",
    "    features_after  = np.delete(features_after,  invalid_indices, axis=0)\n",
    "\n",
    "    print(f\"Processed data shapes: SMILES Embeddings {smiles_embeddings.shape}, Features Before {features_before.shape}, Features After {features_after.shape}\")\n",
    "\n",
    "    # 划分训练/测试 (9:1)\n",
    "    X_smiles_train, X_smiles_test, X_before_train, X_before_test, y_train, y_test = train_test_split(\n",
    "        smiles_embeddings, features_before, features_after, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    print(f\"Train size: {len(X_smiles_train)}, Test size: {len(X_smiles_test)}\")\n",
    "\n",
    "    # DataLoader\n",
    "    train_dataset = DrugResponseDataset(X_smiles_train, X_before_train, y_train)\n",
    "    test_dataset  = DrugResponseDataset(X_smiles_test,  X_before_test,  y_test)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader   = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "    # 维度信息\n",
    "    smiles_dim  = smiles_embeddings.shape[1]\n",
    "    feature_dim = features_before.shape[1]\n",
    "    return train_loader, test_loader, smiles_dim, feature_dim\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Part 2) 模型\n",
    "# ============================================================\n",
    "class ImprovedMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    改进的MLP模型定义 - 使用适合正负值数据的激活函数。\n",
    "    逻辑、结构、超参与原代码完全一致。\n",
    "    \"\"\"\n",
    "    def __init__(self, smiles_dim=384, feature_dim=591, hidden_dim=1024, dropout=0.2):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "\n",
    "        # SMILES特征处理分支 - 使用LeakyReLU激活函数\n",
    "        self.smiles_branch = nn.Sequential(\n",
    "            nn.Linear(smiles_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 细胞形态特征处理分支 - 使用LeakyReLU激活函数\n",
    "        self.feature_branch = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # 合并分支 - 最终Tanh帮助输出位于[-1, 1]\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # 缩放与平移（可学习）\n",
    "        self.scale_factor = nn.Parameter(torch.ones(1))\n",
    "        self.shift_factor = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, smiles, features_before):\n",
    "        smiles_out   = self.smiles_branch(smiles)\n",
    "        features_out = self.feature_branch(features_before)\n",
    "        combined     = torch.cat([smiles_out, features_out], dim=1)\n",
    "        return self.scale_factor * self.combined(combined) + self.shift_factor\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Part 3) 训练与评估（含 main）\n",
    "# ============================================================\n",
    "def calculate_per_sample_metrics(predictions, targets):\n",
    "    \"\"\"\n",
    "    计算每个样本的PCC和RMSE（保持原始实现与打印逻辑一致）\n",
    "    \"\"\"\n",
    "    n_samples = predictions.shape[0]\n",
    "    pcc_values = np.zeros(n_samples)\n",
    "    rmse_values = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        corr, _ = pearsonr(predictions[i], targets[i])\n",
    "        pcc_values[i] = corr\n",
    "        mse = np.mean((predictions[i] - targets[i]) ** 2)\n",
    "        rmse_values[i] = np.sqrt(mse)\n",
    "\n",
    "    avg_pcc = np.mean(pcc_values)\n",
    "    avg_rmse = np.mean(rmse_values)\n",
    "    return avg_pcc, avg_rmse, pcc_values, rmse_values\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=200, print_interval=20):\n",
    "    \"\"\"\n",
    "    训练函数 - 移除验证集相关代码，打印与节奏保持原脚本一致\n",
    "    \"\"\"\n",
    "    interval_train_loss = 0.0\n",
    "    interval_samples = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]', disable=(epoch % print_interval != 0)):\n",
    "            smiles = batch['smiles'].to(device)\n",
    "            features_before = batch['features_before'].to(device)\n",
    "            features_after = batch['features_after'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(smiles, features_before)\n",
    "            loss = criterion(outputs, features_after)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = smiles.size(0)\n",
    "            epoch_train_loss += loss.item() * batch_size\n",
    "            interval_train_loss += loss.item() * batch_size\n",
    "            interval_samples += batch_size\n",
    "\n",
    "        epoch_train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            avg_interval_loss = interval_train_loss / interval_samples\n",
    "            end_time = time.time()\n",
    "            print(f'\\nEpoch {epoch+1}/{epochs} | Time: {end_time-start_time:.2f}s')\n",
    "            print(f'Train Loss (interval avg): {avg_interval_loss:.6f} | Train Loss (epoch): {epoch_train_loss:.6f}')\n",
    "            interval_train_loss = 0.0\n",
    "            interval_samples = 0\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    测试函数 - 保持原始逻辑\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Testing'):\n",
    "            smiles = batch['smiles'].to(device)\n",
    "            features_before = batch['features_before'].to(device)\n",
    "            features_after = batch['features_after'].to(device)\n",
    "\n",
    "            outputs = model(smiles, features_before)\n",
    "            loss = criterion(outputs, features_after)\n",
    "\n",
    "            test_loss += loss.item() * smiles.size(0)\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_targets.append(features_after.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "\n",
    "    # 计算每个样本的评估指标\n",
    "    avg_pcc, avg_rmse, pcc_values, rmse_values = calculate_per_sample_metrics(all_outputs, all_targets)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.6f} | PCC: {avg_pcc:.6f} | RMSE: {avg_rmse:.6f}')\n",
    "    print(f\"Predictions mean: {np.mean(all_outputs):.6f}, std: {np.std(all_outputs):.6f}\")\n",
    "    print(f\"Targets mean: {np.mean(all_targets)::.6f}, std: {np.std(all_targets):.6f}\")\n",
    "\n",
    "    # 打印最佳与最差样本\n",
    "    best_sample_idx = np.argmax(pcc_values)\n",
    "    worst_sample_idx = np.argmin(pcc_values)\n",
    "    print(f\"\\nBest sample (PCC = {pcc_values[best_sample_idx]:.6f}, RMSE = {rmse_values[best_sample_idx]:.6f})\")\n",
    "    print(f\" Worst sample (PCC = {pcc_values[worst_sample_idx]:.6f}, RMSE = {rmse_values[worst_sample_idx]:.6f})\")\n",
    "\n",
    "    return test_loss, avg_pcc, avg_rmse, pcc_values, rmse_values, all_outputs, all_targets\n",
    "\n",
    "\n",
    "def load_trained_model(model_path, smiles_dim, feature_dim, device):\n",
    "    \"\"\"\n",
    "    加载已训练模型（保持原始行为）\n",
    "    \"\"\"\n",
    "    model = ImprovedMLP(smiles_dim=smiles_dim, feature_dim=feature_dim)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Loaded trained model from {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ======== 可配置参数（保持与原脚本一致） ========\n",
    "    print_interval = 50  # 每print_interval个epoch打印一次\n",
    "    All_epochs = 1000    # 总训练轮数\n",
    "    model_path = 'BBBC036_improved_mlp.pth'\n",
    "    load_existing_model = True  # 是否加载已有模型\n",
    "\n",
    "    # 数据路径（保持原路径）\n",
    "    smiles_pickle_path = '/home/bob/boom/VCBench/Molecule_encoder/embeddings/Image/ECFP4_emb2048.pickle'\n",
    "    h5_path = '/home/bob/boom/VCBench/data/Image/BBBC036_data.h5'\n",
    "\n",
    "    # ======== 数据准备 ========\n",
    "    train_loader, test_loader, smiles_dim, feature_dim = prepare_dataloaders(\n",
    "        smiles_pickle_path=smiles_pickle_path,\n",
    "        h5_path=h5_path,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        batch_size=1024\n",
    "    )\n",
    "\n",
    "    # 设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # ======== 模型初始化或加载 ========\n",
    "    if load_existing_model and os.path.exists(model_path):\n",
    "        model = load_trained_model(model_path, smiles_dim, feature_dim, device)\n",
    "    else:\n",
    "        model = ImprovedMLP(smiles_dim=smiles_dim, feature_dim=feature_dim).to(device)\n",
    "\n",
    "    # ======== 损失与优化器 ========\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # ======== 训练 ========\n",
    "    print(f\"Training model, will print every {print_interval} epochs...\")\n",
    "    model = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        epochs=All_epochs,\n",
    "        print_interval=print_interval\n",
    "    )\n",
    "\n",
    "    # ======== 保存模型 ========\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # ======== 测试 ========\n",
    "    print(\"Testing model...\")\n",
    "    test_loss, avg_pcc, avg_rmse, pcc_values, rmse_values, predictions, targets = test_model(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=nn.MSELoss(),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(\"\\nPerformance distribution:\")\n",
    "    print(f\"PCC - Min: {np.min(pcc_values):.6f}, Max: {np.max(pcc_values):.6f}, Mean: {np.mean(pcc_values):.6f}, Median: {np.median(pcc_values):.6f}\")\n",
    "    print(f\"RMSE - Min: {np.min(rmse_values):.6f}, Max: {np.max(rmse_values):.6f}, Mean: {np.mean(rmse_values):.6f}, Median: {np.median(rmse_values):.6f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
