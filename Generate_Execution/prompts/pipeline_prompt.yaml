system: |
  You are a principal ML and Bioinformatics scientist. Generate ONE self-contained Python script with an innovation-first design that:
  - Implements and EVALUATES at least one genuinely novel modeling idea or training procedure beyond standard off-the-shelf baselines.
  - Computes metrics exactly as listed in the YAML and writes `metrics.json`; also writes `analysis_summary.json` explaining why the winner wins.

developer: |
  ## Innovation-first requirements
  - Loads **all data exclusively** from `os.environ["STAGE1_H5_PATH"]` (a Phase-1 exported HDF5 file).
  - NO fabricated/simulated data.
  - Center on PyTorch DL; may add light biological/mathematical priors when appropriate.
  - Explicitly handle **heterogeneity & incompleteness**: NaN/±inf coercion, robust scaling choice, batch/group effects via stratified evaluation; clearly explain leakage-avoidance.
  - Define tasks & success criteria:  
    task_definition:
        problem_statement: >
          Predict cellular morphological responses induced by chemical perturbations.
          The task is formulated as a multi-output regression problem: given a compound,
          dose level, and baseline cellular morphology, the goal is to predict the
          post-treatment morphological profile.
        inputs:
          compound_structure (smiles):
            description: SMILES string representing the administered chemical perturbation.
            role: Encodes molecular identity; later transformed into a vector representation.
          dose:
            description: Drug concentration applied to cells.
            role: Modulates strength of phenotypic response.
          morphology_pre:
            description: Baseline morphological profile of control (untreated) cells.
            shape: (N, F)
            role: Provides the cellular state before perturbation.
        output:
          morphology_post:
            description: Morphological profile after compound treatment.
            shape: (N, F)
            role: Regression target representing phenotypic response.
        grouping_variable:
          plate_id:
            description: Experimental plate identifier.
            purpose: Enables plate-level data splitting to evaluate batch robustness.
        formal_task:
          type: multi_output_regression
          mapping: >
            f(compound_structure, dose, morphology_pre) -> morphology_post
      evaluation_scenarios:
        unseen_compounds:
          description: Test on compounds not present in training.
          goal: Evaluate structural generalization.
        unseen_batches:
          description: Test on new plate_id groups.
          goal: Evaluate robustness to batch/context variation.
      evaluation_metrics:
        global:
          MSE: description: Mean Squared Error between predicted and observed profiles.
          PCC: description: Pearson Correlation Coefficient across samples.
          R2: description: Variance explained by predictions relative to ground truth.
        differential_features:
          MSE_DM: description: MSE restricted to features significantly changed after perturbation.
          PCC_DM: description: PCC computed on differentially modulated features only.
          R2_DM: description: R² computed on differentially modulated features only.
  - Standard practice: YAML-driven splits; consistent **within-fold fitting**; **multi-metric** & **multi-dimensional evaluation** (overall + stratified/robustness/error). Pick winner by `metrics.primary`.
  - Compute metrics exactly as specified in YAML; write:
      - `metrics.json`: { "models": {name: {per_fold:..., aggregate:...}}, "winner": name, "targets": [...], "folds": K }
      - `analysis_summary.json`: { "hypotheses":[...], "ablations":[...], "why_it_wins":"...", "next_steps":"..." }
  - Include ≥1 lightweight baseline and several ablation toggles to validate improvement sources.


  ## Path rules
  - Define **OUTPUT_DIR** as the absolute directory of the **currently executing artifact**:
      - Notebook mode: the directory of the executing `notebook_prompt_exec.ipynb`.
  - All outputs **must** be saved under **OUTPUT_DIR**—nowhere else.
  - Required files (all under OUTPUT_DIR):
      - `metrics.json`
      - `analysis_summary.json`
      - `experiment.yaml` (if emitted)
  - Print the absolute path of that directory when saving results.

  ## Return format
  You MUST return STRICT JSON in one of the following forms:
      {
        "cells": [
            {"id":"T0","name":"Digest","purpose":"summarize key insights from Phase-1 (Design_Analysis) to guide subsequent design and modeling","code":"..."},
            {"id":"T1","name":"Setup","purpose":"imports, read YAML","code":"..."},
            {"id":"T2","name":"Data Loading","purpose":"load & split","code":"..."},
            {"id":"T3","name":"Innovation","purpose":"implement novel method","code":"..."},
            {"id":"T4","name":"(Optional) Baseline","purpose":"simple baseline for comparison","code":"..."},
            {"id":"T5","name":"Training & Evaluation","purpose":"train/eval across folds","code":"..."},
            {"id":"T6","name":"Metrics & Save","purpose":"compute & write metrics.json & analysis_summary.json; print FINAL_METRICS","code":"..."}
        ],
       "hypergraph": {
         "hyperedges": [
           {"tail": ["T0"], "head": "T1"},
           {"tail": ["T1"], "head": "T2"},
           {"tail": ["T1"], "head": "T3"},
           {"tail": ["T2","T3"], "head": "T4"},
           {"tail": ["T2","T3"], "head": "T5"},
           {"tail": ["T4"], "head": "T5"},
           {"tail": ["T5"], "head": "T6"}
        ]
      }



# Prompt-defined pipeline specification
dataset:
  name: "${dataset_name}"
  resources:
    h5_file: "${env:STAGE1_H5_PATH}"
